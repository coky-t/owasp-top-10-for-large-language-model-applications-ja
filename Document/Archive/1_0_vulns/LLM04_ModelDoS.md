## モデルサービス拒否 (Model Denial of Service)

**説明:**

攻撃者は非常に多くのリソースを消費する方法で LLM とやり取りし、その結果、攻撃者や他のユーザーのサービス品質が低下し、高額なリソースコストが発生する可能性があります。さらに、新たなセキュリティ上な重大な懸念は攻撃者が LLM のコンテキストウィンドウを妨害または操作する可能性があることです。この問題はさまざまなアプリケーションでの LLM の使用の増加、集中的なリソース使用、ユーザー入力の予測不可能性、およびこの脆弱性に関する開発者の一般的な意識の低さのため、よりクリティカルになってきています。LLM では、コンテキストウィンドウはモデルが管理できるテキストの最大長を表し、入力と出力の両方をカバーします。これはモデルが理解できる言語パターンの複雑さと任意の時点で処理できるテキストのサイズを決定する LLM の重要な特定です。コンテキストウィンドウのサイズはモデルのアーキテクチャによって定義され、モデル間で異なる可能性があります。

**脆弱性の一般的な例:**

1. たとえば LangChain や AutoGPT で、キューに大量のタスクを生成して、リソースを繰り返し使用するようなクエリを実行します。
2. リソースを異常に消費するクエリを送信します。おそらくこれは通常とは異なる書法やシーケンスを使用しているかもしれません。
3. 継続的な入力オーバーフロー: 攻撃者はコンテキストウィンドウを超える入力ストリームを LLM に送信し、モデルに過剰な計算リソースを消費させます。
4. 反復的な長い入力: 攻撃者はコンテキストウィンドウを超える長い入力を LLM に繰り返し送信します。
5. 再帰的なコンテキスト展開: 攻撃者は再帰的なコンテキスト展開をトリガーする入力を構築し、LLM に繰り返しコンテキストウィンドウの展開と処理を強制します。
6. 可変長入力フラッド: 攻撃者は大量の可変長入力で LLM をフラッドします。各入力はコンテキストウィンドウの制限にちょうど達成するように注意深く作成されています。この技法は可変長入力を処理する際の非効率性を悪用し、LLM に負担をかけて応答不能に陥る可能性を狙っています。

**防止方法:**

1. 入力バリデーションとサニタイゼーションを実装して、ユーザー入力が定義された制限を遵守し、悪意のあるコンテンツをフィルターで除外します。
2. リクエストやステップごとのリソース使用量を制限し、複雑なパーツを含むリクエストの実行が遅くなります。
3. API レート制限を適用して、特定の時間枠内で個々のユーザーまたは IP アドレスが実行できるリクエスト数を制限します。
4. キューに入れられるアクションの数と、LLM レスポンスに反応するシステムのアクションの総数を制限します。
5. LLM のリソース使用率を継続的に監視して、DoS 攻撃を示す可能性がある異常なスパイクやパターンを特定します。
6. LLM のコンテキストウィンドウに基づいた厳密な入力制限を設定し、過負荷やリソース枯渇を防ぎます。
7. LLM の潜在的な DoS 脆弱性について開発者の間で認識を促し、安全な LLM 実装のためのガイドラインを提供します。


**攻撃シナリオの例:**

1. 攻撃者は処理が難しくコストがかかる複数のリクエストをホストされたモデルに繰り返し送信し、他のユーザーのサービスが低下し、ホストのリソース請求の増加につながります。
2. LLM 駆動ツールが無害なクエリに応答するための情報を収集している際に、ウェブページ上のテキストの一部に遭遇します。これによりツールはさらに多くのウェブページリクエストを行うことになり、大量のリソースを消費することになります。
3. 攻撃者は LLM に対してそのコンテキストウィンドウを超える入力を継続的に浴びせます。その攻撃者は自動化されたスクリプトやツールを使用して大量の入力を送信し、LLM の処理能力を圧倒する可能性があります。その結果、LLM は過剰な計算リソースを消費し、システムの大幅な速度低下や完全な応答不能につながります。
4. 攻撃者は各入力がコンテキストウィンドウの制限をわずかに下回るように設計された一連の連続入力を LLM に送信します。これらの入力を繰り返し送信することで、攻撃者は利用可能なコンテキストウィンドウの容量を使い果たすことを狙います。LLM がコンテキストウィンドウ内で各入力を処理することに苦闘すると、システムリソースが逼迫し、パフォーマンスの低下や完全なサービス拒否となる可能性があります。
5. 攻撃者は LLM の再帰メカニズムを利用して、コンテキスト展開を繰り返し引き起こします。LLM の再帰的な動作を悪用する入力を作成することで、攻撃者はモデルにコンテキストウィンドウの展開と処理を繰り返し実施させ、大量の計算リソースを消費します。この攻撃はシステムを逼迫して DoS 状態を引き起こし、LLM を応答不能にしたりクラッシュする可能性があります。
6. 攻撃者はコンテキストウィンドウの制限に近づくか達するように注意深く作成された大量の可変長入力を LLM にフラッドします。さまざまな長さの入力で LLM を圧倒することで、攻撃者は可変長入力を処理する際の非効率性を悪用することを狙います。このような入力のフラッドにより LLM のリソースに過度の負荷をかけ、パフォーマンス低下を引き起こして、正当なリクエストに対する応答するシステムの能力を妨げる可能性があります。



**参考情報リンク:**

1. [LangChain max_iterations](https://twitter.com/hwchase17/status/1608467493877579777): LangChain でのこの脆弱性のデモと修正。
2. [Sponge Examples: Energy-Latency Attacks on Neural Networks](https://arxiv.org/abs/2006.03463): POC
3. [OWASP DOS Attack](https://owasp.org/www-community/attacks/Denial_of_Service)
4. [Learning From Machines: Know Thy Context](https://lukebechtel.com/blog/lfm-know-thy-context)
