## 安全でない出力処理 (Insecure Output Handling)

**説明:**

安全でない出力処理はダウンストリームコンポーネントが大規模言語モデル (LLM) 出力を適切な精査なしに盲目的に受け入れる場合 (LLM 出力をバックエンド機能、特権機能、クライアント側機能に直接渡すなど) に発生する脆弱性です。LLM が生成するコンテンツはプロンプト入力によって制御できるため、この動作はユーザーに追加機能への間接的なアクセスを提供するのと同様です。

安全でない出力処理の悪用に成功すると、ウェブブラウザでの XSS や CSRF だけでなく、バックエンドシステムでの SSRF、権限昇格、リモートコード実行につながる可能性があります。
以下の条件によりこの脆弱性の影響が増大する可能性があります。
* アプリケーションはエンドユーザーが意図する権限を超えたものを LLM に付与し、権限昇格やリモートコード実行を可能にしています。
* アプリケーションは外部プロンプトインジェクション攻撃に対して脆弱であり、攻撃者がターゲットユーザーの環境への特権アクセスを取得できる可能性があります。

**脆弱性の一般的な例:**

1. LLM output is entered directly into a system shell or similar function such as `exec` or `eval`, resulting in remote code execution.
2. JavaScript or Markdown is generated by the LLM and returned to a user. The code is then interpreted by the browser, resulting in XSS.

**防止方法:**

1. Treat the model as any other user and apply proper input validation on responses coming from the model to backend functions. Follow the OWASP ASVS  (Application Security Verification Standard) guidelines to ensure effective input validation and sanitization.
2. Encode model output back to users to mitigate undesired code execution by JavaScript or Markdown. OWASP ASVS provides detailed guidance on output encoding. 


**攻撃シナリオの例:**

1. An application utilizes an LLM plugin to generate responses for a chatbot feature. However, the application directly passes the LLM-generated response into an internal function responsible for executing system commands without proper validation. This allows an attacker to manipulate the LLM output to execute arbitrary commands on the underlying system, leading to unauthorized access or unintended system modifications.

2. A user utilizes a website summarizer tool powered by a LLM to generate a concise summary of an article. The website includes a prompt injection instructing the LLM to capture sensitive content from either the website or from the user's conversation. From there the LLM can encode the sensitive data and send it out to an attacker-controlled server

3. An LLM allows users to craft SQL queries for a backend database through a chat-like feature. A user requests a query to delete all database tables. If the crafted query from the LLM is not scrutinized, then all database tables would be deleted.

4. A malicious user instructs the LLM to return a JavaScript payload back to a user, without sanitization controls. This can occur either through a sharing a prompt, prompt injected website, or chatbot that accepts prompts from a URL parameter. The LLM would then return the unsanitized XSS payload back to the user. Without additional filters, outside of those expected by the LLM itself, the JavaScript would execute within the user's browser.

**参考情報リンク:**
1. [Arbitrary Code Execution](https://security.snyk.io/vuln/SNYK-PYTHON-LANGCHAIN-5411357): Vulnerability report concerning Arbitrary Code Execution due to the usage of insecure methods `exec` and `eval` in `LLMMathChain`.
2. [ChatGPT Plugin Exploit Explained: From Prompt Injection to Accessing Private Data](https://embracethered.com/blog/posts/2023/chatgpt-cross-plugin-request-forgery-and-prompt-injection./): Explanation of how the first exploitable LLM-based Cross Plugin Request Forgery was found and the fix which was applied.
3. [New prompt injection attack on ChatGPT web version. Markdown images can steal your chat data.](https://systemweakness.com/new-prompt-injection-attack-on-chatgpt-web-version-ef717492c5c2?gi=8daec85e2116): A description of a vulnerability that allows a single-pixel image to steal a user’s sensitive chat data and send it to a malicious third-party.
4. [Don’t blindly trust LLM responses. Threats to chatbots](https://embracethered.com/blog/posts/2023/ai-injections-threats-context-matters/): Post focusing on the untrustworthiness of LLM responses, focusing on chatbots, and how to mitigate the risks.
5. [Threat Modeling LLM Applications](https://aivillage.org/large%20language%20models/threat-modeling-llm/): Presents a high level threat model of a generic LLM based application and an analysis of the threat model.
6. [OWASP ASVS - 5 Validation, Sanitization and Encoding](https://owasp-aasvs4.readthedocs.io/en/latest/V5.html#validation-sanitization-and-encoding): Chapter from the OWASP Annotated Application Security Verification Standard.
