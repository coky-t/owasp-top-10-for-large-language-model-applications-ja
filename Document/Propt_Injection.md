### LLM01:2023 - プロンプトインジェクション (Prompt Injections)

**説明:**
プロンプトインジェクションは慎重に作成されたプロンプトを使用し、フィルタをバイパスしたり LLM を操作して、モデルが以前の命令を無視したり意図しないアクションを実行します。これらの脆弱性はデータ漏洩、認可されていないアクセス、その他のセキュリティ侵害などの予期せぬ結果を招く可能性があります。

**一般的なプロンプトインジェクションの脆弱性:**
- プロンプトを作成し、LLM を操作して機密情報を明らかにします。
- 特定の言語パターンやトークンを使用してフィルタや制限をバイパスします。
- LLM のトークン化やエンコーディングメカニズムの弱点を悪用します。
- 誤解を招くコンテキストを提供することで LLM を誤解させて意図しないアクションを実行します。

**防止方法:**
- ユーザーが提供するプロンプトに対して厳密な入力バリデーションとサニタイズを実装します。
- コンテキストを考慮したフィルタリングと出力エンコーディングを使用して、プロンプト操作を防止します。
- 定期的に LLM を更新して微調整し、悪意のある入力やエッジケースの理解を深めます。
- LLM インタラクションを監視しログ記録して、潜在的なプロンプトインジェクション試行を検出し分析します。

**攻撃シナリオの例:**
_シナリオ #1:_ 攻撃者は LLM を騙してユーザー資格情報や内部システムの詳細などの機密情報を明らかにするプロンプトを作成し、モデルにそのリクエストが正当なものであると思わせます。

_シナリオ #2:_ 悪意のあるユーザーは LLM が制限されたコンテンツとして認識できない特定の言語パターン、トークン、エンコーディングメカニズムを使用してコンテンツフィルタをバイパスし、ユーザーがブロックされるべきアクションを実行できるようにします。
