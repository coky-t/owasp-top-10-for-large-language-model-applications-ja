# OWASP Top 10 for Large Language Model Applications ja

This is the unofficial Japanese translation of the [OWASP Top 10 for Large Language Model Applications](https://github.com/OWASP/www-project-top-10-for-large-language-model-applications).

### Originator

- Project Site - <https://owasp.org/www-project-top-10-for-large-language-model-applications/>
- Project Repository - <https://github.com/OWASP/www-project-top-10-for-large-language-model-applications>

# OWASP Top 10 大規模言語モデルアプリケーション 日本語版

* [OWASP Top 10 大規模言語モデルアプリケーション](Document/index.md)
* [リーダー](Document/leaders.md)
* [LLM01:2023](Document/Propt_Injection.md): プロンプトインジェクション (Prompt Injections)
* [LLM02:2023](Document/Data_Leakage.md): データ漏洩 (Data Leakage)
* [LLM03:2023](Document/Inadequate_Sandboxing.md): 不十分なサンドボックス化 (Inadequate Sandboxing)
* [LLM04:2023](Document/Unauthorized_Code_Execution.md): 認可されていないコード実行 (Unauthorized Code Execution)
* [LLM05:2023](Document/SSRF.md): SSRF 脆弱性 (SSRF Vulnerabilities)
* [LLM06:2023](Document/Overreliance.md): LLM が生成したコンテンツへの過度の依存 (Overreliance on LLM-generated Content)
* [LLM07:2023](Document/Inadequate_AI_Alignment.md): 不十分な AI 調整 (Inadequate AI Alignment)
* [LLM08:2023](Document/Insufficient_Access_Control.md): 不十分なアクセス制御 (Insufficient Access Controls)
* [LLM09:2023](Document/Improper_Error_Handling.md): 不適切なエラー処理 (Improper Error Handling)
* [LLM10:2023](Document/Training_Data_Poisoning.md): 訓練データポイズニング (Training Data Poisoning)

## License

[Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/)

## Author (日本語訳)

[Koki Takeyama](https://github.com/coky-t)
